\documentclass[12pt, a4paper]{article} % Класс документа и базовые настройки
\usepackage[utf8]{inputenc} % Кодировка
\usepackage[T2A]{fontenc}   % Кодировка шрифтов для русского
\usepackage[english, russian]{babel} % Поддержка языков (русский основной)
\usepackage{amsmath, amssymb} % Для математических формул
\usepackage{graphicx} % Для вставки картинок
\usepackage{setspace} % Для интервалов
\usepackage{indentfirst}
\setlength{\parindent}{1.25cm} % Размер отступа (обычно 1.25см)
% Отключаем изменение размера шрифта в заголовках
\usepackage{titlesec}
\titleformat*{\section}{\normalfont\normalsize\bfseries}
\titleformat*{\subsection}{\normalfont\normalsize\bfseries}

\title{Экспериментальное исследование способности GNN к выучиванию адаптивных графовых топологий в синтетических многоагентных системах} % Заголовок
\author{Владко Ульяна Алексеевна ИУ6-13М} % Автор
\date{\today} % Дата

\begin{document}

\maketitle % Создает титульный блок

\begin{abstract}
    Настоящее исследование посвящено проверке гипотезы о возможности обучения адаптивной топологии коммуникационного графа в многоагентных системах с помощью GNN. Экспериментально подтверждено, что GNN способны с высокой точностью (ROC-AUC 0.98–0.99) выучивать детерминированные многофакторные правила формирования связей на синтетических данных.
\end{abstract}

\section{Введение} % Раздел

В современных многоагентных системах (МАС) взаимодействие множества автономных агентов позволяет решать сложные задачи в различных областях. Ключевым фактором успеха является коммуникация между агентами, структура которой описывается коммуникационным графом. Эффективность всей системы — скорость принятия решений, отказоустойчивость и общая производительность — напрямую зависит от оптимальности топологии этого графа.

Традиционные статические схемы связи, часто не справляются в динамически меняющихся условиях, когда изменяются расположение агентов, состояние среды, ресурсы или цели. Это приводит к снижению эффективности, запаздыванию реакции и потере информации.

Основная гипотеза исследования заключается в следующем: в МАС, работающей в динамической среде, оптимальная топология коммуникационного графа не может быть фиксированной. Она должна адаптироваться в реальном времени в зависимости от текущего состояния наблюдаемой среды, распределения событий и доступных ресурсов агентов. Цель такой адаптации — максимизация общей скоординированной эффективности системы.

Если гипотеза верна, возникает задача: как выучить эту сложную адаптивную зависимость? Предлагаемым инструментом являются Графовые Нейронные Сети (GNN) — класс моделей глубокого обучения, специально созданный для работы с графами. Их архитектура позволяет агрегировать информацию от соседних узлов (агентов), обрабатывать признаки как узлов, так и связей между ними, и улавливать нелинейные взаимосвязи между локальными данными и глобальной структурой. Таким образом, GNN рассматриваются как ключевой инструмент, способный на основе текущих данных о состоянии агентов и среды предсказывать оптимальную в данный момент конфигурацию коммуникационных связей.

Проверка данной гипотезы и разработка методов на основе GNN имеют большое практическое значение. Это открывает путь к созданию нового поколения МАС — более автономных, гибких и устойчивых. Такие системы смогут не просто реагировать на изменения, но и оптимизировать свои внутренние коммуникации для достижения целей в условиях неопределенности, что критически важно для спасательных операций, автономной разведки, умной логистики и других сложных приложений.

\section{Постановка экспериментальной задачи} % Раздел

Исходная гипотеза является общей для прямой проверки. Чтобы создать контролируемый эксперимент, мы её существенно упростили, сфокусировавшись на ключевом вопросе: способна ли GNN выучить зависимость между состоянием системы и оптимальной топологией связи.

Вместо сложной симуляции реального мира мы используем синтетические графы, где узлы представляют агентов. Их динамическое состояние моделируется изменяющимися численными признаками (например, заряд, компетенция, координаты).

Сложную «максимизацию общей эффективности» заменяем на детерминированное логическое правило (формула (1)). Связь между двумя узлами считается «оптимальной», если их признаки одновременно удовлетворяют набору пороговых условий (например, достаточный заряд у обоих, схожая компетенция, близкое расстояние). Это создаёт однозначную «истинную» топологию для обучения.

% В преамбуле добавьте \usepackage{amsmath}

\begin{equation}
y_{ij} = 
\begin{cases} 
1, & \text{если выполнены все условия:} \\
& \quad \ e_i \geq \tau_e \ \text{и} \ e_j \geq \tau_e \\
& \quad \ |c_i - c_j| \leq \tau_c \\
& \quad \ \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2} \leq \tau_d \\
0, & \text{иначе}
\end{cases}
\label{eq:link_rule}
\end{equation}

\noindent где
$y_{ij} \in \{0, 1\}$ --- метка связи между агентами $i$ и $j$;
$e_i, e_j$ --- уровни энергии агентов;
$c_i, c_j$ --- уровни компетенции агентов;
$x_i, y_i, x_j, y_j$ --- координаты агентов в пространстве;
$\tau_e, \tau_c, \tau_d$ --- пороговые значения.


На вход модели подаётся полносвязный граф. Это позволяет GNN свободно обмениваться информацией между всеми узлами и на основе их признаков самостоятельно «отсеивать» ненужные связи, предсказывая итоговую оптимальную структуру.

\textit{Итоговая проверяемая гипотеза: упрощённой системе, где состояние агентов задано вектором признаков, а оптимальная топология определяется детерминированным правилом, GNN может эффективно обучиться предсказывать эту топологию, получая на вход полносвязный граф и агрегируя информацию на основе признаков узлов}.

\section{Методы и инструменты} % Раздел

Для проверки гипотезы требовался гибкий, итеративный подход к выбору и адаптации методов. Наш инструментарий постоянно эволюционировал, реагируя на возникающие проблемы и стремясь к наглядной демонстрации способности GNN выучивать адаптивные графовые топологии.

Каждый этап этой эволюции — от проектирования синтетических данных до тонкой настройки архитектуры модели и процесса её обучения — был необходим для создания контролируемого, но репрезентативного эксперимента, способного достоверно подтвердить или опровергнуть ядро исходной гипотезы

\subsection{Основной технологический стек} % Подраздел

В основе реализации лежали стандартные для машинного обучения и графовых вычислений инструменты. Python и фреймворк PyTorch были выбраны как основной язык и среда для глубокого обучения благодаря своей гибкости и производительности. Критически важной стала библиотека PyTorch Geometric (PyG), которая предоставила готовые реализации GNN-слоёв (таких как GCNConv и GATConv) и удобные структуры данных для работы с графами, значительно упростив разработку. Для манипуляций с графами и визуализации результатов использовались NetworkX и Matplotlib, что было необходимо для интуитивной оценки работы модели. Для расчёта объективных метрик качества, таких как Accuracy, F1-score и ROC-AUC, применялась библиотека Scikit-learn.

\subsection{Генератор синтетических данных} % Подраздел

Этот модуль претерпел самые значительные изменения, так как именно он формировал саму обучающую задачу для нейронной сети. На начальной, слишком упрощённой стадии, узлы имели всего один числовой признак, а оптимальная связь определялась простым правилом на основе разницы этого признака. Входной граф для GNN при этом был случайным. Это привело к двум ключевым проблемам: катастрофическому дисбалансу классов (где связей «нет» было намного больше, чем связей «да») и нелогичности входной структуры. В результате модель не могла научиться настоящей зависимости и просто предсказывала отсутствие связи.

В промежуточных итерациях мы искали решения. Для борьбы с дисбалансом пробовали регулировать пороги срабатывания правила. В качестве альтернативы, входной граф для GNN был сделан пустым, в надежде, что модель построит топологию «с нуля». Однако ключевым умозаключением стало то, что пустой граф лишает GNN её фундаментальной способности — агрегировать информацию по связям, фактически превращая её в простой многослойный перцептрон (MLP), работающий с изолированными узлами.

На финальной стадии был реализован комплексный подход. Во-первых, признаки узлов были обогащены: каждый агент получил вектор из четырёх числовых характеристик — энергия, компетенция, координата X и координата Y, что позволило смоделировать многомерное состояние (формула (2)).
Во-вторых, «оптимальная» связь стала определяться сложным детерминированным правилом — комбинацией условий по всем признакам (например, оба агента должны иметь энергию выше порога, И разница в их компетенции должна быть мала, И расстояние между ними не должно превышать максимум). Это создало сложную, но однозначную «истину» для обучения. В-третьих, было принято ключевое архитектурное решение: на вход GNN стал подаваться полносвязный граф, где каждый узел потенциально связан со всеми остальными. Это позволило модели свободно обмениваться информацией и на основе признаков самостоятельно «вычислить», какие из этих потенциальных связей должны остаться, формируя оптимальную топологию «с нуля». Параметры правил и пороги тщательно подбирались итеративно для достижения баланса классов (примерно 70/30), что существенно облегчило процесс обучения.

\subsection{Архитектура GNN (SimpleGNN)} % Подраздел

Архитектура самой нейронной сети также развивалась для повышения её выразительной силы. Изначальная простая Graph Convolutional Network (GCN) показала низкие результаты, с ROC-AUC около 0.6. Поэтому был осуществлён переход на Graph Attention Network (GAT). Механизм внимания в GAT позволяет узлам динамически взвешивать важность информации, получаемой от каждого соседа, что оказалось гораздо эффективнее для работы с полносвязным графом, где не все потенциальные связи одинаково значимы.

Далее была проведена работа по увеличению мощности модели: глубина сети увеличена до двух слоёв, размер скрытого представления — до 64 нейронов, а также использовано 8 голов внимания в каждом слое. Это повысило способность модели улавливать сложные нелинейные зависимости. Для стабилизации и ускорения обучения после каждого GAT-слоя были добавлены слои Batch Normalization.

Самым важным изменением в архитектуре стала модификация финального классификатора. Помимо конкатенации векторных представлений (эмбеддингов) двух узлов, в него стала явно подаваться абсолютная разница их признаков (\texttt{torch.abs(x\_row - x\_col)}). Это дало модели прямой доступ к ключевой для нашего детерминированного правила информации — разнице в компетенции и расстоянию между агентами, — что кардинально улучшило её обучаемость и точность.

\subsection{Процесс обучения модели} % Подраздел

Процесс обучения был тщательно настроен. В качестве функции потерь использовался BCEWithLogitsLoss с критически важным параметром \texttt{pos\_weight}. Его значение динамически рассчитывалось для каждого батча, чтобы компенсировать возможный остаточный дисбаланс классов и заставить модель уделять достаточное внимание менее представленным положительным примерам (существующим связям). В качестве оптимизатора применялся Adam со повышением \texttt{learning\_rate = 0.01} и добавленной L2-регуляризацией (\texttt{weight\_decay=1e-5}) для предотвращения переобучения. Основной метрикой успеха был выбран ROC-AUC, так как она устойчива к дисбалансу классов и наилучшим образом оценивает качество ранжирования пар узлов моделью.

\begin{figure}[ht!] % Параметр h! старается поставить картинку тут же
    \centering
    \includegraphics[width=1.1\textwidth]{3} % Замените example-image на имя своего файла
    \caption{История обучения}
    \label{fig:topology_comparison}
\end{figure}

\subsection{Принцин работы} % Подраздел

Начальные признаки каждого агента $i$ представляются вектором:
\begin{equation}
\mathbf{h}_i^{(0)} = [e_i,\ c_i,\ x_i,\ y_i]^T,
\end{equation}
где $e_i$, $c_i$, $x_i$, $y_i$ -- энергия, компетенция и координаты агента.

Входным графом для GNN является полносвязный граф всех агентов.
На каждом слое $l$ представления агентов обновляются по схеме message passing:

\begin{equation}
\mathbf{h}_i^{(l)} = \text{GAT}^{(l)}\left(\mathbf{h}_i^{(l-1)}, \{\mathbf{h}_j^{(l-1)}\}_{j \neq i}\right),
\end{equation}
где $\text{GAT}^{(l)}$ -- слой Graph Attention Network.

После прохождения $L$ слоев получаются финальные представления $\mathbf{h}_i^{(L)}$.
Для предсказания связи между агентами $i$ и $j$ формируется вектор признаков пары:

\begin{equation}
\mathbf{f}_{ij} = \left[ \mathbf{h}_i^{(L)} \ \cdot \mathbf{h}_j^{(L)} \ \cdot  \left|\mathbf{h}_i^{(L)} - \mathbf{h}_j^{(L)}\right| \right],
\end{equation}
где $\left|\mathbf{h}_i^{(L)} - \mathbf{h}_j^{(L)}\right|$ --- разность признаков.

Вероятность наличия оптимальной связи вычисляется как:

\begin{equation}
p_{ij} = \sigma\left(\mathbf{w}^T \mathbf{f}_{ij} + b\right),
\end{equation}
где $\sigma(x) = 1/(1 + e^{-x})$ -- сигмоида, $\mathbf{w}$ и $b$ -- обучаемые параметры классификатора.

Окончательное предсказание определяется пороговым правилом:

\begin{equation}
\hat{y}_{ij} = 
\begin{cases} 
1, & \text{если } p_{ij} \geq 0.8, \\
0, & \text{иначе}.
\end{cases}
\end{equation}

\subsection{Развитие визуализации} % Подраздел

Модуль визуализации эволюционировал от схематичного к информативному и наглядному. Главным улучшением стал переход к пространственному отображению: узлы стали размещаться на графике по их реальным координатам (X, Y), взятым из признаков, вместо использования алгоритмической пружинной укладки (\texttt{spring\_layout}). Это сделало визуализацию интуитивно понятной, особенно для анализа связей, зависящих от расстояния. На узлах добавились детальные подписи с ключевыми значениями признаков, такими как энергия и компетенция. Для удобства сравнения была реализована возможность раздельного отображения трёх состояний: исходного (только узлы), «истинной» оптимальной топологии, вычисленной по правилу, и топологии, предсказанной обученной GNN.

\section{Анализ итеративного процесса разработки} % Раздел

Этот раздел подробно описывает итеративный процесс исследования, где каждый этап был отмечен преодолением конкретных проблем. Доказательно гипотезы требовал проблемно-ориентированный подход.

Первой и фундаментальной проблемой стал начальный дисбаланс классов и отсутствие реального обучения. Модель демонстрировала высокую точность (Accuracy ~90\%), но метрика ROC-AUC, ключевая для задач с несбалансированными данными, стагнировала на уровне 0.5, что эквивалентно случайному угадыванию. Анализ показал, что в сгенерированных данных положительных примеров (оптимальных связей) было катастрофически мало по сравнению с отрицательными. Нейронная сеть, будучи «ленивым учеником», просто выучила тривиальную стратегию — всегда предсказывать отсутствие связи. Для решения мы пошли по трём направлениям. Во-первых, было исправлено техническое несоответствие в генерации меток, где \texttt{edge\_label} и \texttt{edge\_label\_index} имели разную размерность, что вызывало ошибку. Во-вторых, в функцию потерь nn.BCEWithLogitsLoss был введён критически важный параметр \texttt{pos\_weight}, который динамически увеличивал вес ошибок на редком положительном классе, заставляя модель обращать на него внимание. В-третьих, мы начали итеративный подбор порогов и логики в генераторе данных, стремясь к более равномерному распределению классов. Эти меры позволили вывести модель из состояния полного ступора и поднять ROC-AUC до уровня 0.98.

Следующей проблемой стала неэффективная входная структура графа. Несмотря на балансировку, ROC-AUC не мог преодолеть планку в ~0.7. Причина крылась в нашем первоначальном решении подавать на вход GNN пустой \texttt{edge\_index\_input} в надежде, что модель построит топологию «с нуля». Это было фундаментальной ошибкой: без исходных связей механизм обмена сообщениями (message passing) в GNN был неработоспособен, и модель вырождалась в простой многослойный перцептрон, обрабатывающий узлы изолированно. Решением стал переход к полносвязному входному графу. Теперь на каждом слое каждый узел мог агрегировать информацию от всех остальных, формируя богатые, контекстуализированные представления. Это концептуальное изменение подготовило базу для истинного обучения, дав GNN необходимый структурный каркас для анализа взаимосвязей.

Третья, наиболее сложная проблема — недостаточная выразительность модели. Даже с полносвязным графом точность оставалась плохой для детерминированной задачи. Анализ выявил слабость исходной архитектуры GCN, неспособной выделять важные взаимосвязи, и ключевую трудность: модель «теряла» точное значение разницы признаков узлов, которое было центральным в нашем правиле оптимальности (\texttt{abs(comp\_u - comp\_v)}). Наше решение представляло собой комплексный апгрейд архитектуры SimpleGNN. Мы отказались от GCN в пользу Graph Attention Network (GAT), чей механизм внимания позволил узлам динамически взвешивать вклад соседей. Мощность сети была увеличена за счёт трёх слоёв, 128 скрытых каналов и 8 голов внимания. Для стабилизации обучения после каждого слоя добавили Batch Normalization. Важным нововведением стала явная передача абсолютной разницы признаков в финальный классификатор. Код внутри forward функции был изменён: помимо конкатенации эмбеддингов двух узлов, классификатор стал получать на вход вектор \texttt{torch.abs(x\_row - x\_col)}. Это дало модели прямой доступ к информации, критичной для принятия решения. Дополнительная настройка гиперпараметров \texttt{learning rate} и \texttt{weight decay}. В результате ROC-AUC на тестовой выборке уверенно пересёк рубеж в 0.95, что доказало способность GNN с новой архитектурой почти идеально выучивать заданную зависимость.

Четвёртой проблемой стал сохраняющийся или инвертированный дисбаланс при использовании обогащённых признаков. Введение множественных признаков (энергия, компетенция, координаты) и сложных правил их комбинации снова могло приводить к крайнему перекосу в распределении меток — как в сторону почти 100\% отрицательных, так и 100\% положительных примеров, что вновь снижало качество. Проблема была в неточном подборе порогов \texttt{(min\_energy\_threshold, competence\_
diff\_threshold, max\_distance\_threshold)} и логики их объединения (\texttt{'and'/'or'}). Решением стал тщательный, почти ручной итеративный подбор этих параметров в генераторе данных. Цель была: добиться максимально сбалансированного распределения классов (примерно 70/30), создавая для модели сложную, но честную задачу на классификацию. Только достигнув этого баланса, мы смогли в полной мере раскрыть потенциал усовершенствованной архитектуры GNN, что привело к стабильно высоким результатам на уровне ROC-AUC 0.98-0.99.

Так же была проблема неинформативной визуализации, которая мешала интерпретации результатов. Абстрактное расположение узлов через \texttt{spring\_layout} и скудные метки не позволяли понять, почему модель принимает те или иные решения, особенно для связей, зависящих от реального расстояния. Была кардинально переработана функция \texttt{visualize graph}. Визуализация стала пространственной — узлы размещались по их реальным координатам X и Y из признаков. Метки узлов стали отображать ключевые атрибуты (энергию и компетенцию). Реализовано раздельное отображение исходного графа, истинной и предсказанной топологии.

\begin{figure}[ht!] % Параметр h! старается поставить картинку тут же
    \centering
    \includegraphics[width=0.49\textwidth]{1}
    \includegraphics[width=0.49\textwidth]{2} % Замените example-image на имя своего файла
    \caption{Предсказанная GNN оптимальная топология в сравнении с истинной оптимальной топологией}
    \label{fig:topology_comparison}
\end{figure}

\section{Результаты и их верификация} % Раздел

После завершения цикла итеративных оптимизаций, включавших модификацию генератора данных, архитектуры модели и процедуры обучения, была проведена итоговая оценка эффективности предложенного подхода. Количественные показатели, полученные на тестовой выборке, свидетельствуют о высоком качестве решения поставленной синтетической задачи.

\textbf{Ключевые метрики эффективности}

Модель продемонстрировала стабильно высокие результаты на независимых данных. Значение метрики ROC-AUC составило 0.98–0.99, что для задачи бинарной классификации связей свидетельствует о практически идеальном ранжировании пар узлов. Показатель Accuracy находился на уровне 0.95–0.98. Монотонное снижение функции потерь на обучающей и тестовой выборках подтверждает успешную сходимость алгоритма и отсутствие переобучения. Совокупность этих метрик указывает на то, что модель корректно выявила и усвоила целевую функциональную зависимость, заданную детерминированным многофакторным правилом.

\textbf{Подтверждение экспериментальной гипотезы}

Полученные результаты являются строгим эмпирическим подтверждением сформулированной для эксперимента гипотезы. Установлено, что графовая нейронная сеть (в реализованной архитектуре GAT с Batch Normalization и явной передачей разности признаков) способна:

\begin{enumerate}
    \item Интегрировать информацию из многомерных признаков узлов (энергия, компетенция, пространственные координаты).
    \item На основе этих признаков с высокой точностью воспроизводить сложное детерминированное правило формирования связей.
    \item Генерировать адаптивную топологию коммуникационного графа для каждого уникального входного состояния системы, представленного отдельным графом.
\end{enumerate}

Таким образом, в условиях контролируемой синтетической среды доказана принципиальная возможность эффективного обучения GNN задаче адаптивного формирования графовой структуры на основе локальных признаков агентов.

\textbf{Интерпретация в контексте исходной теоретической гипотезы}

Несмотря на существенные упрощения экспериментальной среды, достигнутые результаты имеют значительную объяснительную силу в отношении исходной теоретической гипотезы. Успешное выучивание детерминированной зависимости служит доказательством принципа (Proof of Concept), подтверждающим, что GNN обладают достаточной экспрессивностью для моделирования взаимосвязи между состоянием агентов и оптимальной конфигурацией коммуникационных каналов. Это создаёт теоретико-методологический фундамент для дальнейших исследований. Продемонстрированная способность модели работать с адаптивной топологией напрямую соотносится с ключевым тезисом исходной гипотезы о нестатическом характере оптимальной конфигурации связей. Кроме того, успешное выучивание детерминированного правила, выступавшего в роли абстрактной функции полезности, открывает путь к применению GNN для аппроксимации и максимизации более сложных, вероятностных функций полезности в реальных многоагентных системах, например, с использованием парадигмы обучения с подкреплением.

Таким образом, проведённое исследование не только успешно верифицировало упрощённую гипотезу в синтетической среде, но и эмпирически обосновало перспективность применения графовых нейронных сетей для решения задач адаптивного управления топологией в многоагентных системах, заложив основу для последующей валидации в более реалистичных условиях.

\section{Преимущества и ограничения подхода} % Раздел

Применение графовых нейронных сетей для решения задачи адаптивного формирования топологии выявило ряд ключевых преимуществ данного подхода, а также системные ограничения, требующие учёта при переходе к реальным применениям.

\textbf{Ключевые преимущества}

\textit{Адаптивность на основе данных.} В отличие от жёстко заданных эвристик, GNN способны формировать топологию, динамически подстраиваясь под изменяющиеся условия среды, состояние агентов и цели миссии. Это обеспечивает устойчивость системы в непредсказуемых сценариях.

\textit{Учёт структурной информации.} Архитектура GNN позволяет агрегировать информацию от соседних узлов, формируя обогащённые контекстуальные представления. Это критически важно для задач, где оптимальность связи определяется не изолированными признаками агентов, а их реляционным взаимодействием.

\textit{Способность к обобщению.} Обученная модель демонстрирует высокую обобщающую способность, эффективно предсказывая оптимальные конфигурации для новых, ранее не встречавшихся состояний системы, что принципиально для работы в динамических условиях.

\textit{Интеграция многомерных признаков.} GNN естественным образом обрабатывают векторы признаков произвольной размерности, позволяя учитывать комплексные характеристики агентов (ресурсы, специализация, местоположение) при формировании решения.

\textit{Потенциал для полной автономизации.} Подход открывает путь к созданию систем, самостоятельно оптимизирующих внутреннюю коммуникационную структуру без необходимости ручного программирования сложных правил взаимодействия.

\textbf{Системные ограничения и недостатки}

\textit{Зависимость от размеченных данных.} Эффективное обучение GNN требует значительных объёмов данных с метками «оптимальной» топологии, генерация которых в реальных системах часто невозможна без дорогостоящих симуляций или привлечения экспертов.

\textit{Низкая интерпретируемость.} Принятие решений остаётся в рамках модели «чёрного ящика», что затрудняет анализ и верификацию логики модели, особенно в критически важных приложениях.

\textit{Вычислительная сложность и проблемы масштабируемости.} Обучение и инференс на больших графах (сотни и тысячи узлов) могут требовать неприемлемых вычислительных ресурсов, ограничивая применение в системах реального времени.

\textit{Чувствительность к гиперпараметрам.} Производительность модели критически зависит от тонкой настройки множества параметров архитектуры и обучения, что увеличивает затраты на разработку.

\textit{Сложность определения оптимальности.} В реальных задачах целевая функция (глобальная полезность) часто является многокритериальной, стохастической и неполностью наблюдаемой, что требует выхода за рамки супервизированного обучения, например, к методам обучения с подкреплением.

\textit{Ограниченность статическим представлением.} Базовая модель не учитывает временную динамику. Полноценное прогнозирование оптимальной топологии на следующий шаг требует интеграции методов обработки временных рядов графов, что существенно усложняет модель.

Несмотря на доказанный концептуальный потенциал, практическое внедрение подхода на основе GNN для адаптивного управления топологией в реальных многоагентных системах требует преодоления указанных методологических и инженерных ограничений, что задаёт направления для дальнейших исследований.

\section{Заключение} % Раздел

Ключевые выводы работы заключаются в критической важности сбалансированной генерации данных для обучения, необходимости подачи полносвязного графа на вход модели для эффективной агрегации информации, а также в эффективности адаптации архитектуры GNN (переход к GAT и явное включение разности признаков в классификатор). Процесс исследования носил выраженный итеративный характер, требующий постоянной взаимной коррекции данных и модели.

Полученные результаты формируют доказательство концепции, обосновывая принципиальную применимость GNN для адаптивного управления топологией. Перспективными направлениями дальнейших исследований являются переход к обучению с подкреплением для оптимизации сложных функций полезности, масштабирование подхода на большие графы, интеграция временной динамики и валидация в реалистичных симуляционных средах.

\end{document}